{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport shutil\nimport pathlib\nimport itertools\nfrom PIL import Image\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import regularizers\nfrom IPython.core.display import display, HTML","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_theme(style='darkgrid', palette='pastel')\ncolor = sns.color_palette(palette='pastel')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    flist = os.listdir(foldpath)\n\n    for f in flist:\n        f_path = os.path.join(foldpath, f)\n        filelist = os.listdir(f_path)\n\n        for file in filelist:\n            fpath = os.path.join(f_path, file)\n            filepaths.append(fpath)\n\n            if f == 'colon_aca':\n                labels.append('Colon Adenocarcinoma')\n\n            elif f == 'colon_n':\n                labels.append('Colon Benign Tissue')\n\n            elif f == 'lung_aca':\n                labels.append('Lung Adenocarcinoma')\n\n            elif f == 'lung_n':\n                labels.append('Lung Benign Tissue')\n\n            elif f == 'lung_scc':\n                labels.append('Lung Squamous Cell Carcinoma')\n\n\nfpaths = pd.Series(filepaths, name= 'filepaths')\nlabelss = pd.Series(labels, name='labels')\ndf = pd.concat([fpaths, labelss], axis= 1) #filepaths + labels in 1 df\nprint(df['labels'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train test validation datset \nstrat = df['labels']\ntrain_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state=42, stratify= strat)\n\n\nstrat = dummy_df['labels']\nvalid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state=42, stratify= strat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height=224\nwidth=224\nchannels=3\nbatch_size=40\nimg_shape=(height, width, channels)\nimg_size=(height, width)\nlength=len(test_df)\ntest_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \ntest_steps=int(length/test_batch_size)\nprint ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\ndef scalar(img):\n    return img/127.5-1  # scale pixel between -1 and +1\ngen=ImageDataGenerator(preprocessing_function=scalar)\ntrain_gen=gen.flow_from_dataframe( train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\ntest_gen=gen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\nvalid_gen=gen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\nclasses=list(train_gen.class_indices.keys())\nclass_count=len(classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_griddy_boy(gen ):\n    test_dict=test_gen.class_indices\n    classes=list(test_dict.keys())    \n    images,labels=next(gen) \n    plt.figure(figsize=(20, 20))\n    length=len(labels)\n    if length<25:\n        r=length\n    else:\n        r=25\n    for i in range(r):\n        plt.subplot(5, 5, i + 1)\n        image=(images[i]+1 )/2 \n        plt.imshow(image)\n        index=np.argmax(labels[i])\n        class_name=classes[index]\n        plt.title(class_name, color='blue', fontsize=16)\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_griddy_boy(train_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(train_df, x='labels',width=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_in_color(txt_msg,fore_tupple,back_tupple,):\n    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat), flush=True)\n    print('\\33[0m', flush=True) # returns default print color to back to black\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name='MobileNet'\nbase_model=tf.keras.applications.mobilenet.MobileNet(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling=\"avg\",) \nx=base_model.output\nx=keras.layers.BatchNormalization()(x)\nx = Dense(64,activation='relu')(x)\nx=Dropout(rate=.45)(x)\nx=keras.layers.BatchNormalization()(x)\noutput=Dense(class_count, activation='softmax')(x)\nmodel=Model(inputs=base_model.input, outputs=output)\nmodel.compile(Adagrad(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy',\n                                                                          Precision(name = 'precision'),\n                                                                          Recall(name = 'recall'),\n                                                                          AUC(num_thresholds=200,\n                                                                              curve='ROC',\n                                                                              summation_method='interpolation',\n                                                                              name='auc'),\n                                                                          RootMeanSquaredError(name='root_mean_squared_error')]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LRA(keras.callbacks.Callback):\n    reset=False\n    count=0\n    stop_count=0\n    tepochs=0\n    def __init__(self,model, patience,stop_patience, threshold, factor, dwell, model_name, freeze, initial_epoch):\n        super(LRA, self).__init__()\n        self.model=model\n        self.patience=patience # specifies how many epochs without improvement before learning rate is adjusted\n        self.stop_patience=stop_patience\n        self.threshold=threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n        self.factor=factor # factor by which to reduce the learning rate\n        self.dwell=dwell\n        self.lr=float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initiallearning rate and save it in self.lr\n        self.highest_tracc=0.0 # set highest training accuracy to 0\n        self.lowest_vloss=np.inf # set lowest validation loss to infinity\n        #self.count=0 # initialize counter that counts epochs with no improvement\n        #self.stop_count=0 # initialize counter that counts how manytimes lr has been adjustd with no improvement  \n        self.initial_epoch=initial_epoch \n        #self.epochs=epochs\n        best_weights=self.model.get_weights() # set a class vaiable so weights can be loaded after training is completed        \n        msg=' '\n        if freeze==True:\n            msgs=f' Starting training using  base model { model_name} with weights frozen to imagenet weights initializing LRA callback'\n        else:\n            msgs=f' Starting training using base model { model_name} training all layers '            \n        print_in_color (msgs, (244, 252, 3), (55,65,80)) \n        \n    def on_epoch_begin(self,epoch, logs=None):\n        self.now= time.time()\n        \n    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n        later=time.time()\n        duration=later-self.now        \n        if epoch== self.initial_epoch or LRA.reset==True:  \n            LRA.reset=False           \n            msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^11s}{8:^8s}'.format('Epoch', 'Loss', 'Accuracy','V_loss','V_acc', 'LR', 'Next LR', 'Monitor', 'Duration')\n            print_in_color(msg, (244,252,3), (55,65,80)) \n            \n        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n        current_lr=lr\n        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n        acc=logs.get('accuracy')  # get training accuracy \n        v_acc=logs.get('val_accuracy')\n        loss=logs.get('loss')\n        #print ( '\\n',v_loss, self.lowest_vloss, acc, self.highest_tracc)\n        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n            monitor='accuracy'\n            if acc>self.highest_tracc: # training accuracy improved in the epoch                \n                self.highest_tracc=acc # set new highest training accuracy\n                LRA.best_weights=self.model.get_weights() # traing accuracy improved so save the weights\n                self.count=0 # set count to 0 since training accuracy improved\n                self.stop_count=0 # set stop counter to 0\n                if v_loss<self.lowest_vloss:\n                    self.lowest_vloss=v_loss\n                color= (0,255,0)\n                self.lr=lr\n            else: \n                # training accuracy did not improve check if this has happened for patience number of epochs\n                # if so adjust learning rate\n                if self.count>=self.patience -1:\n                    color=(245, 170, 66)\n                    self.lr= lr* self.factor # adjust the learning by factor\n                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n                    self.count=0 # reset the count to 0\n                    self.stop_count=self.stop_count + 1\n                    if self.dwell:\n                        self.model.set_weights(LRA.best_weights) # return to better point in N space                        \n                    else:\n                        if v_loss<self.lowest_vloss:\n                            self.lowest_vloss=v_loss                                    \n                else:\n                    self.count=self.count +1 # increment patience counter                    \n        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n            monitor='val_loss'\n            if v_loss< self.lowest_vloss: # check if the validation loss improved \n                self.lowest_vloss=v_loss # replace lowest validation loss with new validation loss                \n                LRA.best_weights=self.model.get_weights() # validation loss improved so save the weights\n                self.count=0 # reset count since validation loss improved  \n                self.stop_count=0  \n                color=(0,255,0)\n                self.lr=lr\n            else: # validation loss did not improve\n                if self.count>=self.patience-1:\n                    color=(245, 170, 66)\n                    self.lr=self.lr * self.factor # adjust the learning rate\n                    self.stop_count=self.stop_count + 1 # increment stop counter because lr was adjusted \n                    self.count=0 # reset counter\n                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n                    if self.dwell:\n                        self.model.set_weights(LRA.best_weights) # return to better point in N space\n                else: \n                    self.count =self.count +1 # increment the patience counter                    \n                if acc>self.highest_tracc:\n                    self.highest_tracc= acc\n        msg=f'{str(epoch+1):^3s}/{str(LRA.tepochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{self.lr:^9.5f}{monitor:^11s}{duration:^8.2f}'\n        print_in_color (msg,color, (55,65,80))\n        if self.stop_count> self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n            msg=f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n            print_in_color(msg, (0,255,0), (55,65,80))\n            self.model.stop_training = True # stop training","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs =10\npatience= 1 # number of epochs to wait to adjust lr if monitored value does not improve\nstop_patience =3 # number of epochs to wait before stopping training if monitored value does not improve\nthreshold=.9 # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\nfactor=.5 # factor to reduce lr by\ndwell=True # experimental, if True and monitored metric does not improve on current epoch set  modelweights back to weights of previous epoch\nfreeze=False # if true free weights of  the base model\n\ncallbacks=[LRA(model=model,patience=patience,stop_patience=stop_patience, threshold=threshold,\n                   factor=factor,dwell=dwell, model_name=model_name, freeze=freeze, initial_epoch=0 )]\nLRA.tepochs=epochs  # used to determine value of last epoch for printing\nhistory=model.fit(x=train_gen,  epochs=epochs, verbose=0, callbacks=callbacks,  validation_data=valid_gen,\n               validation_steps=None,  shuffle=False,  initial_epoch=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The training loss is : {history.history['loss'][-1]:0.2f}\\n\")\nprint(f\"The training accuracy is : {(history.history['accuracy'][-1]*100):0.2f}%\\n\")\nprint(f\"The training precision is : {history.history['precision'][-1]:0.2f}\\n\")\nprint(f\"The training recall is : {history.history['recall'][-1]:0.2f}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The validation loss is : {history.history['val_loss'][-1]:0.2f}\\n\")\nprint(f\"The validation accuracy is : {(history.history['val_accuracy'][-1]*100):0.2f}%\\n\")\nprint(f\"The validation precision is : {history.history['val_precision'][-1]:0.2f}\\n\")\nprint(f\"The validation recall is : {history.history['val_recall'][-1]:0.2f}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure , axis = plt.subplots(2,2,figsize=(15,15))\n\n\naxis[0,0].plot(history.history['loss'] , label='train')\naxis[0,0].plot(history.history['val_loss'] , label='val')\naxis[0,0].set_title('Training/validation loss over Epochs')\naxis[0,0].set_xlabel('Epochs')\naxis[0,0].set_ylabel('loss')\naxis[0,0].legend()\n\n\naxis[1,0].plot(history.history['accuracy'], label='train')\naxis[1,0].plot(history.history['val_accuracy'], label='val')\naxis[1,0].set_title('Training/validation accuracy over Epochs')\naxis[1,0].set_xlabel('epoch')\naxis[1,0].set_ylabel('Accuracy')\naxis[1,0].legend()\n\n\naxis[0,1].plot(history.history['precision'], label='train')\naxis[0,1].plot(history.history['val_precision'], label='val')\naxis[0,1].set_title('Training/validation precision over Epochs')\naxis[0,1].set_xlabel('epoch')\naxis[0,1].set_ylabel('Precision')\naxis[0,1].legend()\n\n\naxis[1,1].plot(history.history['recall'], label='train')\naxis[1,1].plot(history.history['val_recall'], label='val')\naxis[1,1].set_title('Training/validation recall over Epochs')\naxis[1,1].set_xlabel('epoch')\naxis[1,1].set_ylabel('Recall')\naxis[1,1].legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts_length = len(test_df)\n\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g_dict = test_gen.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_gen.classes, y_pred, target_names= classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('MobileNetModel.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model('/kaggle/working/MobileNetModel.h5', compile=False)\nloaded_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_aca/lungaca1001.jpeg'\nimage = Image.open(image_path)\n\n# Preprocess the image\nimg = image.resize((224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n\n# Make predictions\npredictions = loaded_model.predict(img_array)\nclass_labels = classes\nscore = tf.nn.softmax(predictions[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}