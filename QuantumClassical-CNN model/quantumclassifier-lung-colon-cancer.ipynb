{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install torch torchvision\n!pip install pennylane","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms, datasets\nfrom torchvision.transforms import ToTensor\nimport torch.optim as optim\nimport torch.nn as nn\nimport pennylane as qml\nfrom pennylane import numpy as np\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport shutil\nimport pathlib\nimport itertools\nfrom PIL import Image\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    flist = os.listdir(foldpath)\n\n    for f in flist:\n        f_path = os.path.join(foldpath, f)\n        filelist = os.listdir(f_path)\n\n        for file in filelist:\n            fpath = os.path.join(f_path, file)\n            filepaths.append(fpath)\n\n            if f == 'colon_aca':\n                labels.append('Colon Adenocarcinoma')\n\n            elif f == 'colon_n':\n                labels.append('Colon Benign Tissue')\n\n            elif f == 'lung_aca':\n                labels.append('Lung Adenocarcinoma')\n\n            elif f == 'lung_n':\n                labels.append('Lung Benign Tissue')\n\n            elif f == 'lung_scc':\n                labels.append('Lung Squamous Cell Carcinoma')\n\n\nfpaths = pd.Series(filepaths, name= 'filepaths')\nlabelss = pd.Series(labels, name='labels')\ndf = pd.concat([fpaths, labelss], axis= 1) #filepaths + labels in 1 df\nprint(df['labels'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n#train test validation datset \nstrat = df['labels']\ntrain_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state=42, stratify= strat)\n\n\nstrat = dummy_df['labels']\nvalid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state=42, stratify= strat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height=224\nwidth=224\nchannels=3\nbatch_size=40\nimg_shape=(height, width, channels)\nimg_size=(height, width)\nlength=len(test_df)\ntest_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \ntest_steps=int(length/test_batch_size)\nprint ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\ndef scalar(img):\n    return img/127.5-1  # scale pixel between -1 and +1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n\n\n# Extract unique labels\nunique_labels = train_df['labels'].unique()\n\n# Create a mapping from string labels to numerical labels\nlabel_map = {label: i for i, label in enumerate(unique_labels)}\n\n# Map string labels to numerical labels in the DataFrame\ntrain_df['numerical_labels'] = train_df['labels'].map(label_map)\n\n# Save the updated DataFrame to a new CSV file\n#df.to_csv('updated_data.csv', index=False)\n\n# Display the first few rows of the updated DataFrame\nprint(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\n\n# Define a custom PyTorch dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # Assuming your DataFrame has 'image' column containing image data and 'label' column containing labels\n        filepath = self.df.iloc[idx]['filepaths']\n        label = self.df.iloc[idx]['numerical_labels']\n        \n        image = Image.open(filepath).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n# Step 1: Convert DataFrame to Custom Dataset\ntransform = transforms.Compose([\n    #transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.Resize((224, 224)),  # Resize images to 32x32\n    transforms.ToTensor(),         # Convert to tensor\n    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize pixel values\n])\n\ntrain_data = CustomDataset(train_df, transform=transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport pennylane as qml\n\n# Define the quantum circuit using PennyLane\nn_qubits = 5\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\n# Define the QLayer\nn_layers = 3\nweight_shapes = {\"weights\": (n_layers, n_qubits)}\n\n\n# Define a simple CNN architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # Convolutional layer 1 with 1 input channels (for greyscale images), 16 output channels, and 5x5 kernel\n        self.conv1 = nn.Conv2d(3, 4, 5, stride=1, padding=2)\n        # Batch normalization after convolutional layer 1\n        self.bn1 = nn.BatchNorm2d(4)\n        # Max pooling layer with a 2x2 window\n        self.pool = nn.MaxPool2d(2, 2)\n        # Convolutional layer 2 with 16 input channels (from the previous layer), 32 output channels, and 5x5 kernel\n        self.conv2 = nn.Conv2d(4, 16, 5, stride=1, padding=2)\n        # Batch normalization after convolutional layer 2\n        self.bn2 = nn.BatchNorm2d(16)\n        # Quantum layer\n        self.qlayer1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n        self.qlayer2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n        self.qlayer3 = qml.qnn.TorchLayer(qnode, weight_shapes)\n        self.qlayer4 = qml.qnn.TorchLayer(qnode, weight_shapes)\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(16 * 56 * 56, 120)\n        self.fc2 = nn.Linear(120, 20)\n        self.fc3 = nn.Linear(20, 10)\n\n    def forward(self, x):\n        # Propagate the input through the CNN layers\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        # Flatten the output from the convolutional layers\n        x = x.view(-1, 16 * 56* 56)\n        # Pass the output to the quantum layer\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x_1, x_2, x_3, x_4 = torch.split(x, 5, dim=1)\n        x_1 = self.qlayer1(x_1)\n        x_2 = self.qlayer2(x_2)\n        x_3 = self.qlayer3(x_3)\n        x_4 = self.qlayer4(x_4)\n        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n        x = self.fc3(x)\n        return x\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\ndataset  = train_data\n\n# Initialize your CNN model\ncnn = Net()\ncnn.to(device)\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\noptimizer = torch.optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)  # Stochastic Gradient Descent optimizer\n# Split your data into training and validation sets\n#train_size = int(0.8 * len(dataset))\n#train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n#val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    ct = datetime.datetime.now()\n    print(f\"{epoch=}, {ct}\")\n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs = inputs.to(device)  # Move inputs to the appropriate device\n        labels = labels.to(device)\n        optimizer.zero_grad()  # Zero the parameter gradients to avoid accumulation\n        outputs = cnn(inputs)  # Forward pass\n        loss = criterion(outputs, labels)  # Compute the loss\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update the model parameters\nprint('Finished Training')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract unique labels\nunique_labels = dummy_df['labels'].unique()\n\n# Create a mapping from string labels to numerical labels\nlabel_map = {label: i for i, label in enumerate(unique_labels)}\n\n# Map string labels to numerical labels in the DataFrame\ndummy_df['numerical_labels'] = dummy_df['labels'].map(label_map)\n\n# Save the updated DataFrame to a new CSV file\n#df.to_csv('updated_data.csv', index=False)\n\n# Display the first few rows of the updated DataFrame\nprint(dummy_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract unique labels\nunique_labels = test_df['labels'].unique()\n\n# Create a mapping from string labels to numerical labels\nlabel_map = {label: i for i, label in enumerate(unique_labels)}\n\n# Map string labels to numerical labels in the DataFrame\ntest_df['numerical_labels'] = test_df['labels'].map(label_map)\n\n# Save the updated DataFrame to a new CSV file\n#df.to_csv('updated_data.csv', index=False)\n\n# Display the first few rows of the updated DataFrame\nprint(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = CustomDataset(test_df, transform=transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\n# Set the model to evaluation mode\ncnn.eval()\nval_loader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False)\nwith torch.no_grad():\n    for data in val_loader:\n        images, labels = data\n        images = images.to(device)  # Move inputs to the appropriate device\n        labels = labels.to(device)\n        outputs = cnn(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\nprint(f'Accuracy on the validation set: {100 * correct / total:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}